{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivaming/PyPractice/blob/master/DL_With_Python_Ch05_Image_Classification_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca-_g4orQP2z"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEdPKozEX9fi"
      },
      "outputs": [],
      "source": [
        "# !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc64hOzEX9ja"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR']='/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcYAI_mkYKhF"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip /content/dogs-vs-cats.zip  -d /content/dogs_cats\n",
        "!unzip /content/dogs_cats/test1.zip -d /content/dogs_cats\n",
        "!unzip /content/dogs_cats/train.zip -d /content/dogs_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eYTFf-_ZJDY"
      },
      "outputs": [],
      "source": [
        "import os, shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rn2a0sVePG0"
      },
      "source": [
        "set up the original directory and sample directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P3ovxM9ZJGS"
      },
      "outputs": [],
      "source": [
        "original_data_dir='/content/dogs_cats'\n",
        "base_dir='/content/dogs_cats_sample'\n",
        "os.mkdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNPw051eMne"
      },
      "outputs": [],
      "source": [
        "for i in ['train', 'validation', 'test']:\n",
        "    new_dir=os.path.join(base_dir, i)\n",
        "    os.mkdir(new_dir)\n",
        "    for n in ['cats', 'dogs']:\n",
        "      new_sub_dir=os.path.join(new_dir, n)\n",
        "      os.mkdir(new_sub_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0Hke6gdLHTF"
      },
      "outputs": [],
      "source": [
        "train_dir='/content/dogs_cats_sample/train'\n",
        "validation_dir='/content/dogs_cats_sample/validation'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn5-MD7eeMqV"
      },
      "outputs": [],
      "source": [
        "file_names=['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/train/cats'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRiSM-OO9Dug"
      },
      "outputs": [],
      "source": [
        "file_names=['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/validation/cats'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD2VUT5l9DxB"
      },
      "outputs": [],
      "source": [
        "file_names=['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/test/cats'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUqSClfp9Dze"
      },
      "outputs": [],
      "source": [
        "file_names=['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/train/dogs'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3HhEWNq9D2Q"
      },
      "outputs": [],
      "source": [
        "file_names=['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/validation/dogs'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49IU00uh9D43"
      },
      "outputs": [],
      "source": [
        "file_names=['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for file_name in file_names:\n",
        "    src=os.path.join(original_data_dir, 'train', file_name)\n",
        "    dst='/content/dogs_cats_sample/test/dogs'\n",
        "    shutil.copy(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frGEYc6x9D7W"
      },
      "outputs": [],
      "source": [
        "len(os.listdir('/content/dogs_cats_sample/train/cats'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9BV-KC5KmL_"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVIGLJ42KI5M"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5w6ajdMKJER"
      },
      "outputs": [],
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255\n",
        "                                 , rotation_range=40\n",
        "                                 , width_shift_range=0.2\n",
        "                                 , height_shift_range=0.2\n",
        "                                 , shear_range=0.2\n",
        "                                 , zoom_range=0.2\n",
        "                                 , horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvkHhwKYKJI4"
      },
      "outputs": [],
      "source": [
        "train_generator=train_datagen.flow_from_directory(\n",
        "    train_dir\n",
        "    , target_size=(150, 150)\n",
        "    , batch_size=20\n",
        "    , class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator=test_datagen.flow_from_directory(\n",
        "    validation_dir\n",
        "    , target_size=(150, 150)\n",
        "    , batch_size=20\n",
        "    , class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq2ddoyvKJL7"
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape: ',  data_batch.shape)\n",
        "    print('label batch shape: ', labels_batch.shape)\n",
        "    print(\"batch: \", labels_batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYLYhHYA2D-V"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puwPtBVTKJNL"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBmScTNi2N_D"
      },
      "outputs": [],
      "source": [
        "# model = models.sequential(\n",
        "#   [\n",
        "#    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "#    layers.MaxPooling2D((2, 2)),\n",
        "#    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#    layers.MaxPooling2D((2, 2)),\n",
        "#    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#    layers.MaxPooling2D((2, 2)),\n",
        "#    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#    layers.MaxPooling2D((2, 2)),\n",
        "#    layers.Flatten(),\n",
        "#    layers.Dense(512, activation='relu'),\n",
        "#    layers.Dense(1, activation='sigmoid')\n",
        "   \n",
        "#   ]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yrYYTVN2OBl"
      },
      "outputs": [],
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI0_TGQY2OEL"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7rHJP3K2OHD"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy'\n",
        "              , optimizer='RMSprop'\n",
        "              , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4pf30uOX2OKP"
      },
      "outputs": [],
      "source": [
        "history=model.fit_generator(train_generator\n",
        "                            , steps_per_epoch=100\n",
        "                            , epochs=100\n",
        "                            , validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDO0K-px2OXG"
      },
      "outputs": [],
      "source": [
        "model.save('cats_and_dogs_2.h5')\n",
        "files.download(\"cats_and_dogs_2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqaEh9dt2OZ0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_6BmbZe2OcZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PKeOgj12Oe1"
      },
      "outputs": [],
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-eHZB8P2Oho"
      },
      "outputs": [],
      "source": [
        "epochs=range(1, len(acc)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE4r8IJVQ11D"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EMKAm72Q13v"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validaton loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g5fu55u4QmSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting features using the pretrained convolutional base"
      ],
      "metadata": {
        "id": "g25Jg9iGehdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Ta2ESvy8Q2B9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_base = VGG16(weights='imagenet'\n",
        "                  , include_top=False\n",
        "                  , input_shape=(150, 150, 3))"
      ],
      "metadata": {
        "id": "OXqFyarDP5Oe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "id": "3CFNVzkTU3Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fe27e7-f9a9-4bdb-c89a-d150957745a0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir='/content/dogs_cats_sample'"
      ],
      "metadata": {
        "id": "8owvqFKag9R6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=os.path.join(base_dir, 'train')\n",
        "validation_dir=os.path.join(base_dir, 'validation')\n",
        "test_dir=os.path.join(base_dir, 'test')"
      ],
      "metadata": {
        "id": "YzvTM6VOfOrM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255)\n",
        "batch_size=20"
      ],
      "metadata": {
        "id": "NY8iECiQfOuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(directory, sample_count):\n",
        "    features=np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "    labels=np.zeros(shape=(sample_count))\n",
        "    generator=datagen.flow_from_directory(\n",
        "        directory\n",
        "        , target_size=(150,150)\n",
        "        , batch_size = batch_size\n",
        "        , class_mode='binary'\n",
        "    )\n",
        "    i=0\n",
        "\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch=conv_base.predict(inputs_batch)\n",
        "        features[i*batch_size:(i+1)*batch_size] = features_batch\n",
        "        labels[i*batch_size:(i+1)*batch_size] = labels_batch\n",
        "        i+=1\n",
        "        if i*batch_size>=sample_count:\n",
        "          break\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "eTFZN3AgfOwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels=extract_features(train_dir, 2000)\n",
        "validation_features, validation_labels=extract_features(validation_dir, 1000)\n",
        "test_features, test_labels=extract_features(test_dir, 1000)"
      ],
      "metadata": {
        "id": "g56uymklfOzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "id": "mV6WbExKWLap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extracted features are currently of shape (samples, 4, 4, 512). You’ll feed them to a densely connected classifier, so first you must flatten them to (samples, 8192)"
      ],
      "metadata": {
        "id": "Ffx9CQ9_glez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features=np.reshape(train_features, (2000, 4*4*512))\n",
        "validation_features=np.reshape(validation_features, (1000, 4*4*512))\n",
        "test_features=np.reshape(test_features, (1000, 4*4*512))"
      ],
      "metadata": {
        "id": "7NXOniP7d7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "id": "cr8Huz9sg6jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "EgxAJx7sd7y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4*4*512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xNItlmrQd72V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='RMSProp'\n",
        "              , loss='binary_crossentropy'\n",
        "              , metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "V3J5ZGh-d75G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_features, train_labels\n",
        "                  , epochs=30\n",
        "                  , batch_size=20\n",
        "                  , validation_data=(validation_features, validation_labels))"
      ],
      "metadata": {
        "id": "-E1HoZ8ffW5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1, len(acc)+1)"
      ],
      "metadata": {
        "id": "VujEO9MBf2eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Db79G1HhqMvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuarcy\")"
      ],
      "metadata": {
        "id": "68qGQ3QvqMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')"
      ],
      "metadata": {
        "id": "6OwbxPtcqMzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cats_and_dogs_3.h5')\n",
        "files.download(\"cats_and_dogs_3.h5\")"
      ],
      "metadata": {
        "id": "k5SWnaMAqM2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XE-4HBF-qM5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "l_OVSejcqM74"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SqFTnthLRPr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "2IOIgz01qM-Z"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "daznAVZnqNAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d8a814-a805-451e-8d4c-82283238c800"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 16,812,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze the conv base"
      ],
      "metadata": {
        "id": "oImNjJ_k6il4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.trainable_weights)"
      ],
      "metadata": {
        "id": "uVuQv02B7_0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e66c44-86d6-466c-c681-3807796361cb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable=False"
      ],
      "metadata": {
        "id": "-ai0iGEYqNC3"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.trainable_weights)"
      ],
      "metadata": {
        "id": "RUhwa8dG8HHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273813a6-e021-4587-f581-7050c3367f47"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "chLbzX539BqL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255\n",
        "    , rotation_range=90\n",
        "    , width_shift_range=0.2\n",
        "    , height_shift_range=0.2\n",
        "    , shear_range=0.2\n",
        "    , zoom_range=0.2\n",
        "    , horizontal_flip=True\n",
        "    ,fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "Sdz-JUKG9BsR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "rAcaqMC_9BvE"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=train_datagen.flow_from_directory(\n",
        "    train_dir\n",
        "    , target_size=(150, 150)\n",
        "    , batch_size=20\n",
        "    , class_mode='binary'    \n",
        ")"
      ],
      "metadata": {
        "id": "4n9MPHM79Bx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66132031-43bc-4516-99a2-e5cb063df55a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator=test_datagen.flow_from_directory(\n",
        "    validation_dir\n",
        "    , target_size=(150, 150)\n",
        "    , batch_size=20\n",
        "    , class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "FJtezdrB9Bz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff79a168-997a-45da-a8f3-ef40a19d392c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy'\n",
        "              #, optimizer='RMSprop'\n",
        "              #, optimizer=optimizers.RMSprop(learning_rate=0.01)\n",
        "              , optimizer='adam'\n",
        "              , metrics=['Accuracy'])"
      ],
      "metadata": {
        "id": "FDg2RErp9B2o"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d6YdSDTdUVc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(train_generator\n",
        "          ### number of training batches = uniqueTrainingData / batchSize\n",
        "          , steps_per_epoch=100\n",
        "          , epochs=30\n",
        "          , validation_data=validation_generator\n",
        "          ### validation_steps = total_validation_samples // validation_batch_size\n",
        "          , validation_steps=50\n",
        "          )"
      ],
      "metadata": {
        "id": "AJLaKMVg9B5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2577ee4-3d61-44f8-bc88-8cb3740d2e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 21s 201ms/step - loss: 0.3250 - Accuracy: 0.8600 - val_loss: 0.2698 - val_Accuracy: 0.8910\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.3268 - Accuracy: 0.8560 - val_loss: 0.2695 - val_Accuracy: 0.8920\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.3433 - Accuracy: 0.8425 - val_loss: 0.2622 - val_Accuracy: 0.8940\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.3377 - Accuracy: 0.8610 - val_loss: 0.2725 - val_Accuracy: 0.8880\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 19s 195ms/step - loss: 0.3409 - Accuracy: 0.8465 - val_loss: 0.2573 - val_Accuracy: 0.8970\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.3322 - Accuracy: 0.8545 - val_loss: 0.2595 - val_Accuracy: 0.8950\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3294 - Accuracy: 0.8495 - val_loss: 0.2616 - val_Accuracy: 0.8950\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3330 - Accuracy: 0.8490 - val_loss: 0.2561 - val_Accuracy: 0.8970\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3125 - Accuracy: 0.8640 - val_loss: 0.2605 - val_Accuracy: 0.8930\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3223 - Accuracy: 0.8575 - val_loss: 0.2590 - val_Accuracy: 0.8970\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3164 - Accuracy: 0.8670 - val_loss: 0.2678 - val_Accuracy: 0.8970\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3395 - Accuracy: 0.8520 - val_loss: 0.2626 - val_Accuracy: 0.8970\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3392 - Accuracy: 0.8475 - val_loss: 0.2598 - val_Accuracy: 0.8930\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.3259 - Accuracy: 0.8485 - val_loss: 0.2595 - val_Accuracy: 0.8970\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3190 - Accuracy: 0.8595 - val_loss: 0.2592 - val_Accuracy: 0.8960\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3255 - Accuracy: 0.8630 - val_loss: 0.2586 - val_Accuracy: 0.8980\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3160 - Accuracy: 0.8650 - val_loss: 0.2680 - val_Accuracy: 0.8990\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3353 - Accuracy: 0.8520 - val_loss: 0.2603 - val_Accuracy: 0.8950\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3165 - Accuracy: 0.8590 - val_loss: 0.2622 - val_Accuracy: 0.8980\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.3353 - Accuracy: 0.8490 - val_loss: 0.2640 - val_Accuracy: 0.8980\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.3075 - Accuracy: 0.8620 - val_loss: 0.2739 - val_Accuracy: 0.8930\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3089 - Accuracy: 0.8630 - val_loss: 0.2715 - val_Accuracy: 0.8950\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.3290 - Accuracy: 0.8490 - val_loss: 0.2594 - val_Accuracy: 0.8930\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.3243 - Accuracy: 0.8525 - val_loss: 0.2656 - val_Accuracy: 0.8950\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3201 - Accuracy: 0.8565 - val_loss: 0.2585 - val_Accuracy: 0.8940\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3002 - Accuracy: 0.8645 - val_loss: 0.2730 - val_Accuracy: 0.8960\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.3339 - Accuracy: 0.8500 - val_loss: 0.2567 - val_Accuracy: 0.8960\n",
            "Epoch 28/30\n",
            " 78/100 [======================>.......] - ETA: 3s - loss: 0.3330 - Accuracy: 0.8442"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cats_and_dogs_4.h5')\n",
        "files.download(\"cats_and_dogs_4.h5\")"
      ],
      "metadata": {
        "id": "yCa36n8MH4nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['Accuracy']\n",
        "val_acc=history.history['val_Accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1, len(acc)+1)"
      ],
      "metadata": {
        "id": "YH5i8yaLFIIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history.history.keys()"
      ],
      "metadata": {
        "id": "fYlwyiBEM_vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0mv2-pLZHt1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuarcy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "9qBuq6pCHt4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GlKCCJffNQ7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "xAreR4ksHt6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YUwwRRNfHt8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test data"
      ],
      "metadata": {
        "id": "UYmVtB9NTemV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator=test_datagen.flow_from_directory(\n",
        "    test_dir\n",
        "    , target_size=(150, 150)\n",
        "    , batch_size=20\n",
        "    , class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "_cv_sSdEHt-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363b2fa6-7523-40a0-cf75-cabed2c3bd97"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc=model.evaluate(test_generator, steps=50)"
      ],
      "metadata": {
        "id": "7ylOYn6yHuBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93582b39-8a7c-4aa2-e30d-08e2432c58e2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 4s 74ms/step - loss: 0.3882 - Accuracy: 0.8590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test accuaracy: \", test_acc)"
      ],
      "metadata": {
        "id": "QSgGRA9qHuEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0d07d2-d188-48ef-8297-5710d85239a4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuaracy:  0.859000027179718\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DL_With_Python_Ch05.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOV04HiwWcbcoqI1k89zi4i",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}